# 后端软件架构

## 一、概述

本系统是一个基于 Electron + LangChain/DeepAgents 的桌面端有声绘本生成应用。后端采用 Express 提供 REST API，与前端通过 Electron IPC 通信，核心 Agent 基于 Deepagents.js 实现多步工作流，支持 LLM 与多模态模型（VL/TTS/T2I）的调度。

---

## 二、基础流程
启动软件进入配置页面，输入appkey。选择案例，按session初始化案例对应的agent，输入想要的绘本内容，agent进行规划，按规划进行模型调度，包括llm和多模态模型。生成最终产物，包括图片和音频，存档到工作空间。

**详细流程**

- **启动与配置**：首次启动需进入配置页输入 API Key；后续启动直接进入欢迎页。欢迎页提供配置按钮，可随时修改配置。
- **会话初始化**：选择案例或历史记录均可初始化 AgentRuntime；选择历史记录时需按 session 加载对应历史。
- **Agent 实例化**：按案例配置实例化 Agent，工作流支持通过配置加载不同案例。
- **HITL 系统**：关键操作需人工确认；结合 checkpoint 支持任意时刻暂停与恢复，可停止任意时长。
- **推理系统**：
  - LLM：基于 OpenAI Chat 兼容接口，可切换 LangChain 其他 provider，使用 llm_apikey。
  - 多模态：兼容各厂商 VL、TTS、T2I 等能力，可扩展；模型由 ai_models.json 配置。
- **链路追踪**：通过 LangSmith 追踪 LLM 与多模态调用，记录 provider、URL、模型等信息。
- **Session 与 Workspace**：按 sessionId 管理会话与工作目录，产物归档到对应 workspace。


**典型案例**
典型是百科类型绘本的生成：
1. 选择百科案例。
2. 输入想生成的百科内容。
3. 确认图片描述。
4. 确认台词。
5. 生成语音。
6. 确认台词序号在图片上的位置。



**主要模块**
1. session管理
通过sessionid进行会话的加载。
2. workspace管理
支持将图片和音频产物，按sessionid保存到对应的工作目录。
3. 用户配置管理
在userdata目录下管理apikey等。
4. agent管理
agent的按案例的构建配置化。
5. inference管理
管理llm模型推理和多模态模型推理。
6. tools
tools封装了当前的一些tools，然后其中封装了一些对多模态模型调用的业务逻辑。
7. mcps
8. subagents


**需要优化的地方**
这里的mcp其实应该按tools进行封装就好了，都给改成tools，subagents就保留一个image_prompt_generator。
llm模型推理和多模态模型推理是需要适配各个provider的，需要进行依赖倒置传入业务模块，tools，mcps，subagents。

---

## 三、目录结构

```
backend/
├── agent/                    # Agent 核心
│   ├── AgentFactory.ts       # Agent 工厂：按案例配置创建主 Agent、SubAgent、Tool
│   ├── ConfigLoader.ts       # 主配置加载器（main_agent_config.yaml）
│   ├── config.ts             # loadConfig 入口
│   ├── fs-routes.ts          # 文件系统 API 路由
│   ├── session-routes.ts     # Session CRUD API 路由
│   ├── LLMCallbacks.ts       # LLM 回调（LangSmith 等）
│   ├── langsmith.ts          # LangSmith 环境初始化
│   └── langsmith-trace.ts    # 多模态调用 trace（VL/TTS/T2I）写入 LangSmith
├── ai/                       # 推理层（统一 provider 抽象）
│   ├── config.ts             # getAIConfig：从 app-config + ai_models.json 解析
│   ├── types.ts              # Provider、AIConfig、LLM/VL/TTS/T2I 类型
│   ├── llm/                  # LLM：dashscope、zhipu
│   ├── vl/                   # 视觉理解：dashscope、zhipu
│   ├── tts/                  # 语音合成：dashscope、zhipu
│   └── t2i/                  # 文生图：dashscope、zhipu
├── mcp/                      # MCP 工具实现（封装多模态调用）
│   ├── t2i.ts                # 文生图
│   ├── tts.ts                # 语音合成
│   ├── vl_script.ts          # 以图生剧本（台词+坐标）
│   ├── annotate_numbers.ts   # 图片数字标注
│   ├── line-numbers.ts       # 台词序号管理
│   └── sync-audio-to-store.ts
├── services/                 # 核心服务
│   ├── service-initializer.ts  # 服务初始化入口
│   ├── fs.ts                 # WorkspaceFilesystem
│   ├── runtime-manager.ts    # AgentRuntime 管理（按 sessionId）
│   ├── persistence-service.ts # Checkpoint 持久化
│   ├── workspace-checkpoint-saver.ts # LangGraph checkpoint 存到 session/checkpoints/
│   ├── workspace-service.ts  # Workspace 增强（配额、权限、审计）
│   ├── hitl-service.ts       # HITL 人工确认
│   └── log-manager.ts        # 日志（audit、hitl、system、llm）
├── config/                   # 配置
│   ├── main_agent_config.yaml
│   ├── ai_models.json        # 各 provider 各能力模型列表
│   ├── hitl-config.ts
│   ├── workspace-config.ts
│   ├── mcp/                  # MCP 能力配置
│   │   ├── t2i_config.yaml
│   │   ├── tts_config.yaml
│   │   └── vl_script_config.yaml
│   └── sub_agents/
│       └── prompt_gen.yaml
└── app-config.ts            # 应用配置（electron-store，userData/config.json）
```

---

## 四、模块关系

| 模块 | 职责 | 依赖 |
|------|------|------|
| **AgentFactory** | 按 main_agent_config 创建主 Agent、SubAgent、Tool | ConfigLoader、ai/config、runtime-manager、hitl-service |
| **RuntimeManager** | 按 sessionId 管理 AgentRuntime（workspace、persistence、log、hitl） | fs、persistence-service、log-manager |
| **WorkspaceFilesystem** | 按 sessionId 读写 workspaces/{sessionId}/，路径安全校验 | 无 |
| **ai/config** | 从 app-config + ai_models.json 解析 provider、apiKey、model | app-config |
| **ai/llm** | 创建 ChatOpenAI，支持 dashscope/zhipu | ai/config |
| **ai/vl, tts, t2i** | 多模态调用，统一 provider 抽象，trace 到 LangSmith | ai/config、langsmith-trace |
| **MCP (t2i, tts, vl_script)** | 封装为 LangChain Tool，内部调用 ai/* | ai/* |
| **HITLService** | 通过 Electron IPC 向前端请求确认，返回 merged payload | 前端 hitl 响应 |

---

## 五、REST API

| 方法 | 路径 | 说明 |
|------|------|------|
| POST | /api/sessions | 创建会话，创建 Runtime |
| GET | /api/sessions | 会话列表 |
| GET | /api/sessions/:sessionId | 会话详情（含 images、audio、llm_logs） |
| PATCH | /api/sessions/:sessionId | 更新会话元数据 |
| DELETE | /api/sessions/:sessionId | 删除会话，关闭 Runtime |

---

## 六、配置体系

| 配置 | 位置 | 说明 |
|------|------|------|
| **config.json** | userData（electron-store） | API Key、provider、model、outputPath、storage 等 |
| **main_agent_config.yaml** | backend/config | 主 Agent、MCP、SubAgent、workflow 定义 |
| **ai_models.json** | backend/config | 各 provider 下 llm/vl/tts/t2i 的 default 与 models 列表 |
| **mcp/*.yaml** | backend/config/mcp | T2I、TTS、VL 的 endpoint、model、default_params |
| **sub_agents/*.yaml** | backend/config/sub_agents | SubAgent 提示词与配置 |

---

## 七、MCP 与 SubAgents 说明

### MCP（现为 Tools 封装）

- **generate_image**：文生图，HITL 确认 prompt 后执行
- **synthesize_speech**：台词合成语音，HITL 确认 texts 后写入 `lines/tts_confirmed.json` 再调用 TTS
- **generate_script_from_image**：以图生剧本（台词+坐标），HITL 确认后执行
- **annotate_image_numbers**：在图片上标注序号，HITL 确认 annotations 后执行
- **delete_artifacts**：删除 session 下产物，HITL 确认 paths 后执行
- **finalize_workflow**：检查图片/音频/台词是否存在，完成工作流

### SubAgents

- **prompt_generator**：根据用户输入生成文生图提示词，写入 `image_prompt.txt`；支持 `createAgent` 或 `createDeepAgent`，可配置 FilesystemMiddleware

### HITL 动作类型

- `ai.text2image`、`ai.text2speech`、`ai.vl_script`、`ai.image_label_order`、`artifacts.delete`

---

## 八、Checkpoint 与持久化

- **WorkspaceCheckpointSaver**：按 `thread_id`（即 sessionId）将 LangGraph checkpoint 存到 `workspaces/{sessionId}/checkpoints/`
- **PersistenceService**：管理 CheckpointSaver 生命周期，支持 `closeCheckpointer(sessionId)`
- **HITL 与 checkpoint**：工具执行前 HITL 等待；用户取消时工具抛错，当前 run 结束；再次发消息时从 checkpoint 恢复，可重新进入同一 HITL 并继续

---

## 九、链路追踪

- **LLM**：LangChain 默认通过 `LANGCHAIN_TRACING_V2`、`LANGCHAIN_API_KEY` 上报
- **多模态**：`ai/vl`、`ai/tts`、`ai/t2i` 通过 `traceAiRun` 写入 LangSmith，记录 provider、model、精简 inputs/outputs

---

## 十、日志规范

**原则**：能被 LangSmith 覆盖的日志视为冗余，应避免输出。

| 类型 | 覆盖方 | 处理 |
|------|--------|------|
| LLM 调用（start/end/inputs/outputs） | LangSmith | 不输出 console |
| 多模态调用（TTS/T2I/VL 的 cfg、body、inputs/outputs） | traceAiRun → LangSmith | 不输出 console |
| Agent 工具调用（t2i、tts、vl_script、finalize_workflow 等执行信息） | LangSmith trace | 不输出 console |
| Agent 初始化（配置加载、工具注册、SubAgent 创建） | 无 | 不输出（非 trace，且易刷屏） |
| 错误/警告（`console.error`、`console.warn`） | 无 | 保留 |
| 系统事件（服务启动、关闭、runtime 创建） | 无 | 保留（logManager.logSystem） |
| LangSmith 启用/禁用提示 | 无 | 保留（启动时一次） |

**保留的日志**：`console.error`、`console.warn` 用于异常与需用户关注的事项；`logManager.logSystem` 用于系统级事件；测试脚本中的 `console.log` 用于调试输出。

---

## 十一、Electron IPC 通道

| 通道 | 说明 |
|------|------|
| config | 配置读写、ai_models.json 加载 |
| storage | 存储路径、输出目录 |
| agent | Agent 创建、invoke、stream |
| session | 会话 CRUD |
| filesystem | 工作空间文件 |
| hitl | HITL 确认请求与响应 |
